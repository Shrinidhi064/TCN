{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9651297,"sourceType":"datasetVersion","datasetId":5895106}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, explained_variance_score\nfrom tqdm import tqdm\n\n# Load dataset\ndata = pd.read_csv('/kaggle/input/futurepred/updatedfuturepredictions.csv')\n\n# Convert 'DateTime' to datetime format if it's not already\ndata['DateTime'] = pd.to_datetime(data['DateTime'])\ndata.set_index('DateTime', inplace=True)  # Set timestamp as index\n\n# Define time intervals based on the index (hour of the day)\nconditions = [\n    (data.index.hour < 6),\n    (data.index.hour >= 6) & (data.index.hour < 12),\n    (data.index.hour >= 12) & (data.index.hour < 17),\n    (data.index.hour >= 17)\n]\ntimeframes = ['Night', 'Morning', 'Afternoon', 'Evening']\n\n# Create a new column for timeframes\ndata['Timeframe'] = np.select(conditions, timeframes)\n\n# Split data into features and target\nX = data.drop(columns=['RZT', 'Timeframe'])  # Drop the target and non-relevant features\ny = data['RZT']\n\n# Drop non-numeric columns (like timestamps) from features\nX = X.select_dtypes(include=[np.number])\n\n# Proceed with train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Ridge Regression model\nridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train)\n\n# Predict and evaluate Ridge Regression\ny_pred_ridge = ridge.predict(X_test)\n\n# Calculate and display metrics\nprint(\"Ridge Regression Metrics:\")\nprint(\"RMSE:\", mean_squared_error(y_test, y_pred_ridge, squared=False))\nprint(\"MAE:\", mean_absolute_error(y_test, y_pred_ridge))\nprint(\"R² Score:\", r2_score(y_test, y_pred_ridge))\nprint(\"MAPE:\", mean_absolute_percentage_error(y_test, y_pred_ridge))\nprint(\"Explained Variance Score:\", explained_variance_score(y_test, y_pred_ridge))\n\n# Generate optimized Ridge predictions for the entire dataset\ndata['RZT_Optimized_Ridge'] = [\n    ridge.predict(X.iloc[[i]])[0] for i in tqdm(range(len(X)), desc=\"Ridge Prediction\")\n]\n\n# Save predictions to Excel\ndata.to_excel('RZT_Optimized_Predictions.xlsx', index=False)\nprint(\"Optimized Ridge predictions saved to 'RZT_Optimized_Predictions.xlsx'.\")\n\n# Calculate min and max RZT for each timeframe\ntimeframe_stats = data.groupby('Timeframe')['RZT_Optimized_Ridge'].agg(['min', 'max']).reset_index()\nprint(\"Optimized Ridge Predictions Min and Max for each Timeframe:\")\nprint(timeframe_stats)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:20:38.674488Z","iopub.execute_input":"2024-10-17T14:20:38.674970Z","iopub.status.idle":"2024-10-17T14:20:48.009190Z","shell.execute_reply.started":"2024-10-17T14:20:38.674917Z","shell.execute_reply":"2024-10-17T14:20:48.008154Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Ridge Regression Metrics:\nRMSE: 0.00010859386576204629\nMAE: 8.556138843053161e-05\nR² Score: 0.9999999983732062\nMAPE: 4.385661556390377e-06\nExplained Variance Score: 0.9999999983734356\n","output_type":"stream"},{"name":"stderr","text":"Ridge Prediction: 100%|██████████| 7200/7200 [00:08<00:00, 897.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Optimized Ridge predictions saved to 'RZT_Optimized_Predictions.xlsx'.\nOptimized Ridge Predictions Min and Max for each Timeframe:\n   Timeframe        min        max\n0  Afternoon  17.374215  31.460924\n1    Evening  17.368994  31.774783\n2    Morning  17.333801  34.608553\n3      Night  17.338181  32.897261\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,\n                             mean_absolute_percentage_error, explained_variance_score,\n                             median_absolute_error, max_error, mean_squared_log_error,\n                             mean_poisson_deviance, mean_tweedie_deviance)\n\n# Calculate and display multiple metrics\nprint(\"Ridge Regression Metrics:\")\nprint(\"1. RMSE:\", mean_squared_error(y_test, y_pred_ridge, squared=False))\nprint(\"2. MAE:\", mean_absolute_error(y_test, y_pred_ridge))\nprint(\"3. Median Absolute Error:\", median_absolute_error(y_test, y_pred_ridge))\nprint(\"4. R² Score:\", r2_score(y_test, y_pred_ridge))\nprint(\"5. MAPE:\", mean_absolute_percentage_error(y_test, y_pred_ridge))\nprint(\"6. Explained Variance Score:\", explained_variance_score(y_test, y_pred_ridge))\nprint(\"7. Max Error:\", max_error(y_test, y_pred_ridge))\nprint(\"8. Mean Squared Log Error:\", mean_squared_log_error(y_test, y_pred_ridge))\nprint(\"9. Mean Poisson Deviance:\", mean_poisson_deviance(y_test, y_pred_ridge))\nprint(\"10. Mean Tweedie Deviance:\", mean_tweedie_deviance(y_test, y_pred_ridge))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:21:02.526938Z","iopub.execute_input":"2024-10-17T14:21:02.527944Z","iopub.status.idle":"2024-10-17T14:21:02.545902Z","shell.execute_reply.started":"2024-10-17T14:21:02.527889Z","shell.execute_reply":"2024-10-17T14:21:02.544814Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Ridge Regression Metrics:\n1. RMSE: 0.00010859386576204629\n2. MAE: 8.556138843053161e-05\n3. Median Absolute Error: 7.251602758628906e-05\n4. R² Score: 0.9999999983732062\n5. MAPE: 4.385661556390377e-06\n6. Explained Variance Score: 0.9999999983734356\n7. Max Error: 0.00036322018203804873\n8. Mean Squared Log Error: 2.650877633197765e-11\n9. Mean Poisson Deviance: 5.811804568464948e-10\n10. Mean Tweedie Deviance: 1.179262768114533e-08\n","output_type":"stream"}],"execution_count":4}]}